# ShowUI-Ï€: Flow-based Generative Models as GUI Dexterous Hands

Unified discrete-continuous actions for free-form drag computer use.

<p align="center">
  ğŸ“‘ <a href="https://arxiv.org/abs/2512.24965">Paper</a>
  &nbsp;|&nbsp;
  ğŸŒ <a href="https://showlab.github.io/showui-pi/">Project Page</a>
</p>

## Demo

https://raw.githubusercontent.com/showlab/showui-pi/page/assets/showui-pi-demo.mp4

<p align="center">
  <a href="https://raw.githubusercontent.com/showlab/showui-pi/page/assets/showui-pi-demo.mp4">
    <img src="https://raw.githubusercontent.com/showlab/showui-pi/page/assets/teaser_static.png" alt="ShowUI-Ï€ demo" width="720">
  </a>
</p>

## Overview

ShowUI-Ï€ is a 450M flow-based vision-language-action model that treats GUI actions as continuous trajectories, generating smooth clicks and drags directly from screen observations. It unifies discrete and continuous actions, enabling precise drawing, rotation, sorting, and captcha solving without tokenized coordinates.

## ğŸ“ BibTeX

If you find our work helpful, please kindly consider citing our paper.

```bibtex
@misc{hu2025showuipi,
  title={ShowUI-$\\pi$: Flow-based Generative Models as GUI Dexterous Hands},
  author={Siyuan Hu and Kevin Qinghong Lin and Mike Zheng Shou},
  year={2025},
  eprint={2512.24965},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  doi={10.48550/arXiv.2512.24965},
  url={https://arxiv.org/abs/2512.24965},
}
```

## License

This project is licensed under the Apache License, Version 2.0.
See `LICENSE` for details.
